__author__ = "Ivan Infante and Felipe Zapata"

# ================> Python Standard  and third-party <==========
import numpy as np
import os
import pyparsing as pa
from scipy.optimize import curve_fit
from scipy.spatial.distance import cdist

# ==================> Internal modules <==========
from nac.common import (hbar, h2ev, r2meV, fs_to_cm)
from qmflows.parsers import parse_string_xyz
from nac.schedule.components import split_file_geometries
# ==========================<>=================================


def autocorrelate(f):
    """
    Compute and returns the un-normalized and normalized autocorrelation
    of given function
    """
    d_f = f - f.mean()
    # Compute the autocorrelation function
    uacf = np.correlate(d_f, d_f, "full")[-d_f.size:] / d_f.size
    # Compute the normalized autocorrelation function
    nacf = uacf / uacf[0]
    return uacf, nacf


def gauss_function(x, sigma):
    """
    Gaussian function used to fit the dephasing time
    """
    return np.exp(-0.5 * (-x / sigma) ** 2)


def func_conv(x_real, x_grid, delta):
    """
    A Gaussian function computed on a grid used to convolute spectra
    """
    return np.exp(-2 * (x_grid - x_real) ** 2 / delta ** 2)


def convolute(x, y, x_points, sigma):
    """
    A function used to convolute spectra on a grid of x_points.
    You need as input x, y and the grid where to convolute.
    """
    # Compute gaussian prefactor
    prefactor = np.sqrt(2.0) / (sigma * np.sqrt(np.pi))
    # Convolute spectrum over grid
    y_points = prefactor * np.stack(
        np.sum(y * func_conv(x, x_point, sigma)) for x_point in x_points)
    return y_points


def dephasing(f, dt):
    """
    Computes the dephasing time of a given function using optical response
    formalisms:
    S. Mukamel, Principles of Nonlinear Optical Spectroscopy, 1995
    About the implementation we use the 2nd order cumulant expansion.
    See also eq. (2) in : Kilina et al. Phys. Rev. Lett., 110, 180404, (2013)
    To calculate the dephasing time tau we fit the dephasing function to a
    gaussian of the type : exp(-0.5 * (-x / tau) ** 2)
    """
    # Conversion of hbar to hartree * fs
    hbar_au = hbar / h2ev
    ts = np.arange(f.shape[0]) * dt
    cumu_ii = np.stack(np.sum(f[0:i]) for i in range(ts.size)) * dt / hbar_au
    cumu_i = np.stack(np.sum(cumu_ii[0:i]) for i in range(ts.size)) * dt / hbar_au
    deph = np.exp(-cumu_i)
    np.seterr(over='ignore')
    popt = curve_fit(gauss_function, ts, deph)[0]
    xs = np.exp(-0.5 * (-ts / popt[0]) ** 2)
    deph = np.column_stack((deph, xs))
    deph_time = popt[0]  # in fs
    line_broadening = hbar / deph_time  # in eV
    return deph, deph_time, line_broadening


def spectral_density(f, dt):
    """
    Fourier Transform of a given function f using a dense grid with 100000 points.
    In the case of a FFT of a normalized autocorrelation function,
    this corresponds to a spectral density
    """
    f_fft = abs(1 / np.sqrt(2 * np.pi) * np.fft.fft(f, 100000) * dt) ** 2
    # Fourier Transform of the time axis
    freq = np.fft.fftfreq(len(f_fft), dt)
    # Conversion of the x axis (given in cycles/fs) to cm-1
    freq = freq * fs_to_cm
    return f_fft, freq


def read_couplings(path_hams, ts):
    """
    This function reads the non adiabatic coupling vectors from the files
    generated for the NAMD simulations
    """
    files_im = [os.path.join(path_hams, 'Ham_{}_im'.format(i)) for i in range(ts)]
    xs = np.stack(np.loadtxt(fn) for fn in files_im)
    return xs * r2meV  # return energies in meV


def read_energies(path_hams, ts):
    """
    This function reads the molecular orbital energies of each state from
    the files generated for the NAMD simulations
    """
    files_re = [os.path.join(path_hams, 'Ham_{}_re'.format(i)) for i in range(ts)]
    xs = np.stack(np.diag(np.loadtxt(fn)) for fn in files_re)
    return xs * r2meV / 1000  # return energies in eV


def read_energies_pyxaid(path, fn, nstates, nconds):
    """
    This function reads the molecular orbital energies of each state from
    the output files generated by PYXAID
    """
    inpfile = os.path.join(path, fn)
    cols = tuple(range(5, nstates * 2 + 5, 2))
    xs = np.stack(np.loadtxt('{}{}'.format(inpfile, j), usecols=cols)
                  for j in range(nconds)).transpose()
    # Rows = timeframes ; Columns = states ; tensor = initial conditions
    xs = xs.swapaxes(0, 1)
    return xs


def read_pops_pyxaid(path, fn, nstates, nconds):
    """
    This function reads the population of each state from
    the output files generated by PYXAID
    """
    inpfile = os.path.join(path, fn)
    cols = tuple(range(3, nstates * 2 + 3, 2))
    xs = np.stack(np.loadtxt('{}{}'.format(inpfile, j), usecols=cols)
                  for j in range(nconds)).transpose()
    # Rows = timeframes ; Columns = states ; tensor = initial conditions
    xs = xs.swapaxes(0, 1)
    return xs


def rdf(fn, atoms_i, atoms_j, dr, rmax):
    """
    A function that computes the radial distribution function between a pair of atoms
    """
    # Read the geometries from the MD file
    geometries = split_file_geometries(fn)
    molecs = [parse_string_xyz(gs) for gs in geometries]

    # Get the number of atoms and number of frames in trajectory file
    n_frames = len(molecs)
    n_atoms = len(molecs[0])

    # Create grid of r values to compute the pair correlation function g_ij
    r_grid = np.arange(0, rmax, dr)
    # Used for the histogram
    n_bins = r_grid.size

    # Find the indexes in the bond_matrix of the atomic types involved in the calculation of g_ij
    atoms = np.asarray([molecs[0][i].symbol for i in range(n_atoms)])
    index_i = np.where(atoms == atoms_i)
    index_j = np.where(atoms == atoms_j)

    rdf_tot = np.zeros(n_bins)
    for iframe in range(n_frames):
        # Read coordinates from iframe
        coords = np.asarray([molecs[iframe][i].xyz for i in range(n_atoms)])
        # Compute bond distance matrix for iframe
        bond_mtx = cdist(coords, coords)
        # Slice the bond_matrix with only the atom types
        sliced_mtx = np.triu(bond_mtx[np.ix_(index_i[0], index_j[0])])
        # Count the number of atoms within r and r+dr
        rdf, r_grid = np.histogram(sliced_mtx, bins=n_bins, range=(0, rmax))
        # Sum over all rdf
        rdf_tot += rdf

    # Center radii
    r = 0.5 * (r_grid[1:] + r_grid[:-1])
    # Compute the volume in a concentric sphere of size dr at a distance r from the origin
    # elemental volume dV = 4*pi*r^2*dr
    volume = (4/3) * np.pi * (np.power(r_grid[1:], 3) - np.power(r_grid[:-1], 3))
    vol_tot = np.sum(volume)
    # Compute the rho_ab(r)
    # This is the pair density distribution for each frame
    rho_ab = rdf_tot / (volume * n_frames)
    # Compute the bulk density
    # skip first element otherwise it counts an atom with itself
    n_tot = np.sum(rdf_tot[1:]) / n_frames
    rho_bulk = n_tot / vol_tot
    # Density = counts / volume[1:] # skip the first element dV which is 0
    g_ab = rho_ab / rho_bulk
    # Compute also the potential of mean force
    w_ab = -np.log(g_ab)

    # we skip the first element at r=0, which in the histogram is counted many times:
    # counts an atom with itself
    return r[1:], g_ab[1:], w_ab[1:]


def parse_list_of_lists(xs):
    """
    Parse a list of list of integers using pyparsing
    """
    enclosed = pa.Forward()  # Parser to be defined later
    natural = pa.Word(pa.nums)  # Natural Number
    # Nested Grammar
    nestedBrackets = pa.nestedExpr(pa.Suppress('['), pa.Suppress(']'), content=enclosed)
    enclosed << (natural | pa.Suppress(',') | nestedBrackets)
    try:
        rs = enclosed.parseString(xs).asList()[0]
        return list(map(lambda x: list(map(int, x)), rs))
    except pa.ParseException:
        raise RuntimeError("Invalid Macro states Specification")
